#!/usr/bin/env python3
"""
arxiv_notifier.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
* AI ìš”ì•½ í† ê¸€: AI_SUMMARIZE = True / False
* DAYS_BACK: ìµœê·¼ N ì¼ ë…¼ë¬¸ë§Œ ë©”ì¼ì— í¬í•¨
* GPT ëª¨ë¸â€†Â·â€†API í‚¤ëŠ” í™˜ê²½ë³€ìˆ˜(OPENAI_API_KEY)ë¡œ ê´€ë¦¬
"""

from __future__ import annotations

import email.utils as eut
import hashlib
import json
import os
import smtplib
from urllib.parse import quote_plus
from datetime import date, datetime, timedelta, timezone
from email.header import Header
from email.mime.text import MIMEText
from typing import Any, Dict, List, Optional

import feedparser

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ AI ìš”ì•½ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AI_SUMMARIZE = True  # â† ì¼œê±°ë‚˜ ë”
MODEL_ID = "gpt-4.1"
if AI_SUMMARIZE:
    import openai

    openai.api_key = os.getenv("OPENAI_API_KEY")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ENV_VARS = ("EMAIL_ADDRESS", "EMAIL_PASSWORD", "TO_EMAIL")
TOPIC_FILE = "topics.json"
MAX_RESULTS_DEFAULT = 20
DAYS_BACK = 3  # ìµœê·¼ N ì¼
TITLE_MAX, ABSTRACT_MAX = 120, 600
GLOBAL_EXCLUDE = {"review", "survey", "comment on", "corrigendum"}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ í•¨ìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def getenv_or_exit(name: str) -> str:
    v = os.getenv(name)
    if not v:
        raise SystemExit(f"[config] '{name}' í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤")
    return v


def load_topics(path: str) -> Dict[str, Any]:
    with open(path, encoding="utf-8") as fh:
        return json.load(fh)


def make_query(keyword: str, cats: list[str]) -> str:
    """
    * ë‹¤ë‹¨ì–´ í‚¤ì›Œë“œ â†’ "ë¬¸êµ¬ ê²€ìƒ‰" (ë„ì–´ì“°ê¸° ìœ ì§€)
    * ë‹¨ì¼ ë‹¨ì–´ì¼ ë•Œ ìë™ìœ¼ë¡œ ì ‘ë¯¸ * ì¶”ê°€ (ì´ë¯¸ * ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ)
    """
    if " " in keyword:
        # "neutral atom" â†’ "%22neutral+atom%22"
        phrase = quote_plus(keyword, safe="")  # URL-encode
        kw_part = f"(ti:%22{phrase}%22+OR+abs:%22{phrase}%22)"
    else:
        token = keyword if "*" in keyword else f"{keyword}*"
        kw_part = f"(ti:{token}+OR+abs:{token})"

    if cats:
        cat_part = "+OR+".join(f"cat:{c}" for c in cats)
        return f"({cat_part})+AND+{kw_part}"
    return kw_part


def fetch_entries(q: str, n: int) -> List[Any]:
    url = (
        "http://export.arxiv.org/api/query?search_query="
        f"{q}&start=0&max_results={n}"
        "&sortBy=submittedDate&sortOrder=descending"
    )
    return feedparser.parse(url).entries


def _get_entry_datetime(entry) -> Optional[datetime]:
    for field in ("published", "updated", "created"):
        val = getattr(entry, field, None)
        if not val:
            continue
        tup = eut.parsedate_tz(val)
        if tup:
            return datetime.fromtimestamp(eut.mktime_tz(tup), tz=timezone.utc)
    return None


def is_recent(entry) -> bool:
    dt = _get_entry_datetime(entry)
    if dt is None:
        return False
    return dt >= datetime.now(tz=timezone.utc) - timedelta(days=DAYS_BACK)


def truncate(txt: str, limit: int) -> str:
    return txt if len(txt) <= limit else txt[: limit - 3].rstrip() + "..."


def summarize(title: str, abstract: str) -> str:
    resp = openai.chat.completions.create(
        model=MODEL_ID,
        messages=[
            {
                "role": "system",
                "content": (
                    "You are a scientific summarizer.\n"
                    "Return exactly three lines:\n"
                    "1) Problem: <one concise sentence>\n"
                    "2) Result: <one concise sentence>\n"
                    "3) Method: <one concise sentence>"
                ),
            },
            {"role": "user", "content": f"TITLE: {title}\nTEXT: {abstract}"},
        ],
        temperature=0.3,
        max_tokens=120,
    )
    return resp.choices[0].message.content.strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë…¼ë¬¸ ìˆ˜ì§‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def collect_papers(topics: Dict[str, Any]) -> Dict[str, List[Dict[str, str]]]:
    out, seen = {}, set()
    for topic, cfg in topics.items():
        papers = []
        for kw in cfg.get("keywords", []):
            for e in fetch_entries(
                make_query(kw, cfg.get("categories", [])),
                int(cfg.get("max_results", MAX_RESULTS_DEFAULT)),
            ):
                if not is_recent(e):
                    continue
                uid = hashlib.sha1(e.id.encode()).hexdigest()
                if uid in seen:
                    continue
                seen.add(uid)

                title = " ".join(e.title.split())
                abstract = " ".join(e.summary.split())
                if any(k in abstract.lower() for k in GLOBAL_EXCLUDE):
                    continue

                info = {
                    "title": truncate(title, TITLE_MAX),
                    "link": e.link,
                    "abstract": truncate(abstract, ABSTRACT_MAX),
                }
                if AI_SUMMARIZE:
                    try:
                        info["summary"] = summarize(title, abstract)
                    except Exception as err:
                        info["summary"] = f"(ìš”ì•½ ì‹¤íŒ¨: {err})"

                papers.append(info)
        if papers:
            out[topic] = papers
    return out


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¼ ë³¸ë¬¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_email(papers: Dict[str, List[Dict[str, str]]]) -> str:
    lines = ["ğŸ“°  ì˜¤ëŠ˜ì˜ arXiv\n"]
    for i, (topic, plist) in enumerate(papers.items()):
        lines += [f"ğŸ“Œ {topic.upper()} ({len(plist)})", "=" * (len(topic) + 7)]
        for j, p in enumerate(plist, 1):
            if AI_SUMMARIZE:
                lines.append("   ğŸ’¡ 3-line summary(GPT-4.1):")
                for ln in p["summary"].splitlines():
                    lines.append(f"      {ln}")
                lines.append("")
            lines += [
                f"{j}. ğŸ“„ {p['title']}",
                f"   ğŸ”— {p['link']}\n",
                "   ğŸ“ Abstract:",
                f"      {p['abstract']}\n",
            ]
            if j < len(plist):
                lines.append("   " + "-" * 40 + "\n")
        if i < len(papers) - 1:
            lines.append("ãƒ»" * 30 + "\n")
    lines += [
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        f"ì§€ë‚œ {DAYS_BACK}ì¼ ì´ë‚´ ì œì¶œëœ ë…¼ë¬¸ë§Œ í¬í•¨í–ˆìŠµë‹ˆë‹¤.",
    ]
    return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì´ë©”ì¼ ë°œì†¡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def send_email(
    subject: str,
    body: str,
    sender: str,
    pwd: str,
    recipients: list[str],
) -> None:
    msg = MIMEText(body, "plain", "utf-8")
    msg["Subject"], msg["From"] = subject, sender
    msg["To"] = ", ".join(recipients)

    with smtplib.SMTP("smtp.gmail.com", 587) as s:
        s.starttls()
        s.login(sender, pwd)
        s.sendmail(sender, recipients, msg.as_string())


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main() -> None:
    sender, pwd, rcpt_raw = (getenv_or_exit(k) for k in ENV_VARS)
    recipients = [e.strip() for e in rcpt_raw.split(",") if e.strip()]

    papers = collect_papers(load_topics(TOPIC_FILE))
    if not papers:
        print("[info] no new papers")
        return

    first_topic, first_list = next(iter(papers.items()))
    subject = str(
        Header(
            f"{date.today():%Y-%m-%d} - ì˜¤ëŠ˜ì˜ arXiv - "
            f"{first_topic} ({len(first_list)})",
            "utf-8",
        )
    )
    send_email(subject, build_email(papers), sender, pwd, recipients)
    print("[ok] email sent")


if __name__ == "__main__":
    main()
